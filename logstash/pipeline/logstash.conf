input {
  tcp {
    port => 5000
    type => "nginx_access" # 為Nginx日誌添加類型
  }
  beats {
    port => 5044
  }
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => ["elk-input"]
    group_id => "logstash"
    auto_offset_reset => "latest"
  }
}

filter {
  # 剖析Nginx存取日誌
  if [type] == "nginx_access" {
    grok {
      match => { "message" => "%{COMBINEDAPACHELOG}" }
    }
  }

  # 可以在這裡添加過濾規則
  if [type] == "syslog" {
    grok {
      match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
    }
    date {
      match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
    }
  }
}

output {
  elasticsearch {
    hosts => ["https://elasticsearch:9200"]
    index => "logstash-%{+YYYY.MM.dd}"
    user => "elastic"
    password => "${ELASTIC_PASSWORD}"
    cacert => "/usr/share/logstash/config/certs/ca.crt"
    ssl => true
  }
  stdout {
    codec => rubydebug
  }
}
