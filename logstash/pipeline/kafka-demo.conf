# ./logstash/pipeline/kafka-demo.conf
input {
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => ["demo"]
    group_id => "logstash-demo"
    auto_offset_reset => "earliest"
    codec => "json"
  }
}

filter {
  # 你的 JSON 是 "timestamp"，轉成 ES 可用的 @timestamp
  date {
    match  => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }

  # 可選：統一欄位命名，方便 Kibana/Elastic 方案
  mutate {
    rename => { "service" => "service.name" }
    rename => { "level"   => "log.level" }
  }
}

output {
  # 傳到 Elasticsearch（HTTP 有開 TLS）
  elasticsearch {
    hosts    => ["https://elasticsearch:9200"]
    user     => "elastic"
    password => "${ELASTIC_PASSWORD}"
    ssl_enabled => true
    ssl_certificate_authorities => "/usr/share/logstash/config/certs/ca.crt"
    index    => "kafka-demo-%{+YYYY.MM.dd}"
  }

  # 除錯輸出（可觀察 Logstash 端是否有吃到資料）
  stdout { codec => rubydebug }
}
